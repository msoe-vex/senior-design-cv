{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Localization Demonstration Notebook\n",
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Imported Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.load('best_torchscript.pt')\n",
    "\n",
    "with open('best_torchscript.pt', 'rb') as f:\n",
    "    buffer = io.BytesIO(f.read())\n",
    "\n",
    "model = torch.jit.load(buffer, map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring constant variables, obtained from values in Intel and VRC documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = ((448.0-172.0) * 24.0) / 11.0\n",
    "width_dict = {\"Ring\":3.5, \"Neutral_Goal\":12.5, \"Blue_Goal\":12.5, \"Red_Goal\":12.5, \"Blue_Robot\":5.5, \"Red_Robot\":5.5, \"Blue_Platform\":53.0, \"Red_Platform\":53.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting image pipeline from D435 camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No device connected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_455148/1037070065.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbgr8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: No device connected"
     ]
    }
   ],
   "source": [
    "pipeline = rs.pipeline()\n",
    "config = rs.config()\n",
    "config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "pipeline.start(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object localization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_distance(obj):\n",
    "    # kitti file parsing\n",
    "    obj_array = obj.split()\n",
    "    x_min, y_min, x_max, y_max = float(obj_array[4]), float(obj_array[5]), float(obj_array[6]), float(obj_array[7])\n",
    "    \n",
    "    # calculating centroid of object\n",
    "    centroid_x, centroid_y = int((x_min+x_max)/2.), int((y_min+y_max)/2.)\n",
    "    \n",
    "    # calculating distance using trigonometric properties\n",
    "    trig_distance = (width_dict[obj_array[0]] * focal_length)/(x_max - x_min) \n",
    "    \n",
    "    # extract average distance from depth map and convert to inches\n",
    "    depth_distance_meters = (depth_frame.get_distance(centroid_x, centroid_y) +\\\n",
    "                             depth_frame.get_distance(centroid_x+5, centroid_y) +\\\n",
    "                             depth_frame.get_distance(centroid_x, centroid_y+5) +\\\n",
    "                             depth_frame.get_distance(centroid_x-5, centroid_y) +\\\n",
    "                             depth_frame.get_distance(centroid_x, centroid_y-5))/5.0\n",
    "    depth_distance = 39.3701 * depth_distance_meters\n",
    "    \n",
    "    # weighting and combining localization methods\n",
    "    distance = (trig_distance * .2) + (depth_distance_meters * .8) \n",
    "    \n",
    "    # in the event that depthmap can't detect distance, only use trig distance\n",
    "    if (depth_distance_meters == 0):\n",
    "        distance = trig_distance\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using identification and localization to process images from the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # extracting data from the image pipeline\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    \n",
    "    # IO for trained YOLOv5 model (color_img->game_objects)\n",
    "    # TODO Fix localization output acceptance\n",
    "    img_resized = cv2.resize(color_image, (640, 640)).reshape(1, 3, 640, 640)\n",
    "    game_objects = model(torch.Tensor(img_resized))[0].shape\n",
    "    \n",
    "#     # reading labels from kitti file\n",
    "#     game_objects = []\n",
    "#     with open('img_kitti.txt') as f:\n",
    "#         game_objects = f.readlines()   \n",
    "    \n",
    "    # calculating distance for all game objects in frame\n",
    "    for obj in game_objects:\n",
    "        print(f'{obj.split()[0]}: {obj_distance(obj)})')\n",
    "    \n",
    "    # closing the identification models output file\n",
    "    f.close()\n",
    "    # 0.1 second buffer to prevent pipeline from bottlenecking\n",
    "    time.sleep(.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
