{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Localization Demonstration Notebook\n",
    "### Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import time\n",
    "# TODO import trained YOLOv4 object identification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring constant variables, obtained from values in Intel and VRC documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_length = ((448.0-172.0) * 24.0) / 11.0\n",
    "width_dict = {\"Ring\":3.5, \"Neutral_Goal\":12.5, \"Blue_Goal\":12.5, \"Red_Goal\":12.5, \"Blue_Robot\":5.5, \"Red_Robot\":5.5, \"Blue_Platform\":53.0, \"Red_Platform\":53.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declaring and initializing trained YOLOv4 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO declare YOLOv4 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting image pipeline from D435 camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No device connected",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_375572/488476290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: No device connected"
     ]
    }
   ],
   "source": [
    "pipeline = rs.pipeline()\n",
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Object localization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obj_distance(obj):\n",
    "    # kitti file parsing\n",
    "    obj_array = obj.split()\n",
    "    x_min, y_min, x_max, y_max = float(obj_array[4]), float(obj_array[5]), float(obj_array[6]), float(obj_array[7])\n",
    "    \n",
    "    # calculating centroid of object\n",
    "    centroid_x, centroid_y = int((x_min+x_max)/2.), int((y_min+y_max)/2.)\n",
    "    \n",
    "    # calculating distance using trigonometric properties\n",
    "    trig_distance = (width_dict[obj_array[0]] * focal_length)/(x_max - x_min) \n",
    "    \n",
    "    # extract distance from depth map and convert to inches\n",
    "    depth_distance_meters = depth_frame.get_distance(centroid_x, centroid_y) \n",
    "    depth_distance = 39.3701 * depth_distance_meters\n",
    "    \n",
    "    # weighting and combining localization methods\n",
    "    distance = (trig_distance * .2) + (depth_distance_meters * .8) \n",
    "    \n",
    "    # in the event that depthmap can't detect distance, only use trig distance\n",
    "    if (depth_distance_meters == 0):\n",
    "        distance = trig_distance\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using identification and localization to process images from the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "wait_for_frames cannot be called before start()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_375572/670429614.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# extracting data from the image pipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_for_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdepth_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_depth_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcolor_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_color_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: wait_for_frames cannot be called before start()"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # extracting data from the image pipeline\n",
    "    frames = pipeline.wait_for_frames()\n",
    "    depth_frame = frames.get_depth_frame()\n",
    "    color_frame = frames.get_color_frame()\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    \n",
    "    # TODO add IO for trained YOLOv4 model (color_img->img_kitti_file)\n",
    "    \n",
    "    # reading labels from kitti file\n",
    "    game_objects = []\n",
    "    with open('img_kitti.txt') as f:\n",
    "        game_objects = f.readlines()   \n",
    "    \n",
    "    # calculating distance for all game objects in frame\n",
    "    for obj in game_objects:\n",
    "        print(f'{obj.split()[0]}: {obj_distance(obj)})')\n",
    "    \n",
    "    # closing the identification models output file\n",
    "    f.close()\n",
    "    # 0.1 second buffer to prevent pipeline from bottlenecking\n",
    "    time.sleep(.1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
